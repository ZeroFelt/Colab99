{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZeroFelt/Colab99/blob/main/%E2%80%9CNovelAILeaks_API_Backend_(4chan_Ver_)%E2%80%9D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZ88G-iWCTs7"
      },
      "source": [
        "基于 4chan 魔改版 NovelAILeaks (naifu) 制作。[来源](https://boards.4channel.org/g/thread/89095460#p89097704)\n",
        "\n",
        "使用官方前端 + 优化版后端，可突破75限制，支持所有模型。\n",
        "\n",
        "Credit: https://t.me/StableDiffusion_CN https://t.me/exlolicon\n",
        "\n",
        "Thanks: Anonymous, 炼铜术士, 神楽坂早苗️, Jonathan, 咕 咕, 猫又逆变器, Gaein nidb\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQcqz7P6tr7J"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLgD73pxF212"
      },
      "source": [
        "0. 检查 GPU 工作状态"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X5yF8TS1CR3L"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlTMB-MwF4lC"
      },
      "source": [
        "1. 下载 Novel AI API 后端、模型 （如果下载速度太慢可尝试 restart）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqTO_Uf3F6VW",
        "outputId": "f49cd5a2-bd37-475e-a88a-aa1e46e97e2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  libc-ares2\n",
            "The following NEW packages will be installed:\n",
            "  aria2 libc-ares2\n",
            "0 upgraded, 2 newly installed, 0 to remove and 12 not upgraded.\n",
            "Need to get 1,274 kB of archives.\n",
            "After this operation, 4,912 kB of additional disk space will be used.\n",
            "Selecting previously unselected package libc-ares2:amd64.\n",
            "(Reading database ... 123934 files and directories currently installed.)\n",
            "Preparing to unpack .../libc-ares2_1.14.0-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking libc-ares2:amd64 (1.14.0-1ubuntu0.1) ...\n",
            "Selecting previously unselected package aria2.\n",
            "Preparing to unpack .../aria2_1.33.1-1_amd64.deb ...\n",
            "Unpacking aria2 (1.33.1-1) ...\n",
            "Setting up libc-ares2:amd64 (1.14.0-1ubuntu0.1) ...\n",
            "Setting up aria2 (1.33.1-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.6) ...\n",
            "\n",
            "10/13 00:54:09 [\u001b[1;32mNOTICE\u001b[0m] Downloading 2 item(s)\n",
            " *** Download Progress Summary as of Thu Oct 13 00:54:15 2022 *** \n",
            "=\n",
            "[#635f2c 406MiB/7.4GiB(5%) CN:3 DL:80MiB ETA:1m29s]\n",
            "FILE: /content/naifu.tar\n",
            "-\n",
            "[#fb2b01 511MiB/7.1GiB(6%) CN:3 DL:93MiB ETA:1m13s]\n",
            "FILE: /content/animefull-latest.tar\n",
            "-\n",
            "\n",
            " *** Download Progress Summary as of Thu Oct 13 00:54:20 2022 *** \n",
            "=\n",
            "[#635f2c 0.9GiB/7.4GiB(12%) CN:3 DL:93MiB ETA:1m10s]\n",
            "FILE: /content/naifu.tar\n",
            "-\n",
            "[#fb2b01 1.0GiB/7.1GiB(14%) CN:3 DL:95MiB ETA:1m5s]\n",
            "FILE: /content/animefull-latest.tar\n",
            "-\n",
            "\n",
            " *** Download Progress Summary as of Thu Oct 13 00:54:26 2022 *** \n",
            "=\n",
            "[#635f2c 1.5GiB/7.4GiB(20%) CN:3 DL:101MiB ETA:59s]\n",
            "FILE: /content/naifu.tar\n",
            "-\n",
            "[#fb2b01 1.5GiB/7.1GiB(22%) CN:3 DL:93MiB ETA:1m1s]\n",
            "FILE: /content/animefull-latest.tar\n",
            "-\n",
            "\n",
            " *** Download Progress Summary as of Thu Oct 13 00:54:32 2022 *** \n",
            "=\n",
            "[#635f2c 2.1GiB/7.4GiB(28%) CN:3 DL:100MiB ETA:54s]\n",
            "FILE: /content/naifu.tar\n",
            "-\n",
            "[#fb2b01 2.2GiB/7.1GiB(30%) CN:3 DL:101MiB ETA:50s]\n",
            "FILE: /content/animefull-latest.tar\n",
            "-\n",
            "\n",
            " *** Download Progress Summary as of Thu Oct 13 00:54:38 2022 *** \n",
            "=\n",
            "[#635f2c 2.6GiB/7.4GiB(35%) CN:3 DL:93MiB ETA:52s]\n",
            "FILE: /content/naifu.tar\n",
            "-\n",
            "[#fb2b01 2.7GiB/7.1GiB(38%) CN:3 DL:95MiB ETA:47s]\n",
            "FILE: /content/animefull-latest.tar\n",
            "-\n",
            "\n",
            " *** Download Progress Summary as of Thu Oct 13 00:54:44 2022 *** \n",
            "=\n",
            "[#635f2c 3.2GiB/7.4GiB(43%) CN:3 DL:100MiB ETA:42s]\n",
            "FILE: /content/naifu.tar\n",
            "-\n",
            "[#fb2b01 3.3GiB/7.1GiB(46%) CN:3 DL:102MiB ETA:38s]\n",
            "FILE: /content/animefull-latest.tar\n",
            "-\n",
            "\n",
            " *** Download Progress Summary as of Thu Oct 13 00:54:50 2022 *** \n",
            "=\n",
            "[#635f2c 3.8GiB/7.4GiB(51%) CN:3 DL:100MiB ETA:36s]\n",
            "FILE: /content/naifu.tar\n",
            "-\n",
            "[#fb2b01 3.9GiB/7.1GiB(54%) CN:3 DL:98MiB ETA:34s]\n",
            "FILE: /content/animefull-latest.tar\n",
            "-\n",
            "\n",
            " *** Download Progress Summary as of Thu Oct 13 00:54:56 2022 *** \n",
            "=\n",
            "[#635f2c 4.3GiB/7.4GiB(59%) CN:3 DL:98MiB ETA:31s]\n",
            "FILE: /content/naifu.tar\n",
            "-\n",
            "[#fb2b01 4.4GiB/7.1GiB(62%) CN:3 DL:96MiB ETA:28s]\n",
            "FILE: /content/animefull-latest.tar\n",
            "-\n",
            "\n",
            " *** Download Progress Summary as of Thu Oct 13 00:55:02 2022 *** \n",
            "=\n",
            "[#635f2c 4.8GiB/7.4GiB(65%) CN:3 DL:90MiB ETA:28s]\n",
            "FILE: /content/naifu.tar\n",
            "-\n",
            "[#fb2b01 4.9GiB/7.1GiB(68%) CN:3 DL:93MiB ETA:24s]\n",
            "FILE: /content/animefull-latest.tar\n",
            "-\n",
            "\n",
            " *** Download Progress Summary as of Thu Oct 13 00:55:08 2022 *** \n",
            "=\n",
            "[#635f2c 5.5GiB/7.4GiB(74%) CN:3 DL:95MiB ETA:20s]\n",
            "FILE: /content/naifu.tar\n",
            "-\n",
            "[#fb2b01 5.4GiB/7.1GiB(76%) CN:3 DL:84MiB ETA:20s]\n",
            "FILE: /content/animefull-latest.tar\n",
            "-\n",
            "\n",
            " *** Download Progress Summary as of Thu Oct 13 00:55:14 2022 *** \n",
            "=\n",
            "[#635f2c 6.0GiB/7.4GiB(81%) CN:3 DL:93MiB ETA:15s]\n",
            "FILE: /content/naifu.tar\n",
            "-\n",
            "[#fb2b01 6.0GiB/7.1GiB(84%) CN:3 DL:92MiB ETA:12s]\n",
            "FILE: /content/animefull-latest.tar\n",
            "-\n",
            "\n",
            " *** Download Progress Summary as of Thu Oct 13 00:55:20 2022 *** \n",
            "=\n",
            "[#635f2c 6.5GiB/7.4GiB(88%) CN:3 DL:89MiB ETA:9s]\n",
            "FILE: /content/naifu.tar\n",
            "-\n",
            "[#fb2b01 6.5GiB/7.1GiB(91%) CN:3 DL:96MiB ETA:6s]\n",
            "FILE: /content/animefull-latest.tar\n",
            "-\n",
            "\n",
            " *** Download Progress Summary as of Thu Oct 13 00:55:26 2022 *** \n",
            "=\n",
            "[#635f2c 7.1GiB/7.4GiB(96%) CN:3 DL:96MiB ETA:3s]\n",
            "FILE: /content/naifu.tar\n",
            "-\n",
            "[#fb2b01 7.0GiB/7.1GiB(98%) CN:3 DL:89MiB ETA:1s]\n",
            "FILE: /content/animefull-latest.tar\n",
            "-\n",
            "\n",
            "\u001b[0m\n",
            "10/13 00:55:27 [\u001b[1;32mNOTICE\u001b[0m] Download complete: /content/animefull-latest.tar\n",
            "\u001b[0m\n",
            "10/13 00:55:29 [\u001b[1;32mNOTICE\u001b[0m] Download complete: /content/naifu.tar\n",
            "\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "fb2b01|\u001b[1;32mOK\u001b[0m  |    93MiB/s|/content/animefull-latest.tar\n",
            "635f2c|\u001b[1;32mOK\u001b[0m  |    95MiB/s|/content/naifu.tar\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n"
          ]
        }
      ],
      "source": [
        "%cd /content/\n",
        "!apt install -y -qq aria2\n",
        "!aria2c --summary-interval=5 -x 3 --allow-overwrite=true -Z \\\n",
        "  https://pub-2fdef7a2969f43289c42ac5ae3412fd4.r2.dev/naifu.tar \\\n",
        "  https://pub-2fdef7a2969f43289c42ac5ae3412fd4.r2.dev/animefull-latest.tar \n",
        "  \n",
        "!tar xf naifu.tar && rm naifu.tar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyD6cZlYGPpU"
      },
      "source": [
        "2. 安装依赖"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BysBfYRmGSo1",
        "outputId": "48b096fd-8d02-4651-e7d9-71385ec71016"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/naifu\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: virtualenv in /usr/local/lib/python3.7/dist-packages (20.16.5)\n",
            "Requirement already satisfied: platformdirs<3,>=2.4 in /usr/local/lib/python3.7/dist-packages (from virtualenv) (2.5.2)\n",
            "Requirement already satisfied: filelock<4,>=3.4.1 in /usr/local/lib/python3.7/dist-packages (from virtualenv) (3.8.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.3 in /usr/local/lib/python3.7/dist-packages (from virtualenv) (5.0.0)\n",
            "Requirement already satisfied: distlib<1,>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from virtualenv) (0.3.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.3->virtualenv) (3.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.3->virtualenv) (4.1.1)\n",
            "+ virtualenv venv\n",
            "created virtual environment CPython3.7.14.final.0-64 in 311ms\n",
            "  creator CPython3Posix(dest=/content/naifu/venv, clear=False, no_vcs_ignore=False, global=False)\n",
            "  seeder FromAppData(download=False, pip=bundle, setuptools=bundle, wheel=bundle, via=copy, app_data_dir=/root/.local/share/virtualenv)\n",
            "    added seed packages: Markdown==3.4.1, MarkupSafe==2.1.1, Pillow==9.2.0, PyWavelets==1.3.0, PyYAML==6.0, Werkzeug==2.2.2, absl_py==1.2.0, aiohttp==3.8.3, aiosignal==1.2.0, antlr4_python3_runtime==4.9.3, anyio==3.6.1, async_timeout==4.0.2, asynctest==0.13.0, attrs==22.1.0, cachetools==5.2.0, certifi==2022.9.24, charset_normalizer==2.1.1, click==8.1.3, dotmap==1.3.30, einops==0.5.0, faiss_cpu==1.7.2, fastapi==0.85.0, filelock==3.8.0, frozenlist==1.3.1, fsspec==2022.8.2, ftfy==6.1.1, google_auth==2.12.0, google_auth_oauthlib==0.4.6, grpcio==1.49.1, h11==0.14.0, huggingface_hub==0.10.1, idna==3.4, imageio==2.22.1, importlib_metadata==5.0.0, importlib_resources==5.10.0, joblib==1.2.0, jsonmerge==1.8.0, jsonschema==4.16.0, multidict==6.0.2, networkx==2.6.3, nltk==3.7, numpy==1.21.6, oauthlib==3.2.1, omegaconf==2.2.3, packaging==21.3, pip==22.2.2, pkgutil_resolve_name==1.3.10, protobuf==3.19.6, pyDeprecate==0.3.2, pyasn1==0.4.8, pyasn1_modules==0.2.8, pydantic==1.10.2, pyparsing==3.0.9, pyrsistent==0.18.1, pytorch_lightning==1.7.7, regex==2022.9.13, requests==2.28.1, requests_oauthlib==1.3.1, rsa==4.9, scikit_image==0.19.3, scikit_learn==1.0.2, scipy==1.7.3, sentence_transformers==2.2.2, sentencepiece==0.1.97, setuptools==65.3.0, six==1.16.0, sniffio==1.3.0, starlette==0.20.4, tensorboard==2.10.1, tensorboard_data_server==0.6.1, tensorboard_plugin_wit==1.8.1, threadpoolctl==3.1.0, tifffile==2021.11.2, tokenizers==0.13.1, torch==1.12.1+cu116, torchaudio==0.12.1+cu116, torchdiffeq==0.2.3, torchmetrics==0.10.0, torchvision==0.13.1+cu116, tqdm==4.64.1, transformers==4.23.1, typing_extensions==4.4.0, urllib3==1.26.12, uvicorn==0.18.3, wcwidth==0.2.5, wheel==0.37.1, yarl==1.8.1, zipp==3.9.0\n",
            "  activators BashActivator,CShellActivator,FishActivator,NushellActivator,PowerShellActivator,PythonActivator\n",
            "+ . venv/bin/activate\n",
            "++ '[' venv/bin/activate = ./setup.sh ']'\n",
            "++ deactivate nondestructive\n",
            "++ unset -f pydoc\n",
            "++ '[' -z '' ']'\n",
            "++ '[' -z '' ']'\n",
            "++ hash -r\n",
            "++ '[' -z '' ']'\n",
            "++ unset VIRTUAL_ENV\n",
            "++ '[' '!' nondestructive = nondestructive ']'\n",
            "++ VIRTUAL_ENV=/content/naifu/venv\n",
            "++ '[' linux-gnu = cygwin ']'\n",
            "++ '[' linux-gnu = msys ']'\n",
            "++ export VIRTUAL_ENV\n",
            "++ _OLD_VIRTUAL_PATH=/opt/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin\n",
            "++ PATH=/content/naifu/venv/bin:/opt/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin\n",
            "++ export PATH\n",
            "++ '[' -z '' ']'\n",
            "++ '[' -z '' ']'\n",
            "++ _OLD_VIRTUAL_PS1=\n",
            "++ '[' x '!=' x ']'\n",
            "+++ basename /content/naifu/venv\n",
            "++ PS1='(venv) '\n",
            "++ export PS1\n",
            "++ alias pydoc\n",
            "++ true\n",
            "++ hash -r\n",
            "+ pip install -r requirements.txt\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://download.pytorch.org/whl/cu116\n",
            "Requirement already satisfied: torch in ./venv/lib/python3.7/site-packages (from -r requirements.txt (line 2)) (1.12.1+cu116)\n",
            "Requirement already satisfied: torchvision in ./venv/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (0.13.1+cu116)\n",
            "Requirement already satisfied: torchaudio in ./venv/lib/python3.7/site-packages (from -r requirements.txt (line 4)) (0.12.1+cu116)\n",
            "Requirement already satisfied: dotmap in ./venv/lib/python3.7/site-packages (from -r requirements.txt (line 5)) (1.3.30)\n",
            "Requirement already satisfied: fastapi in ./venv/lib/python3.7/site-packages (from -r requirements.txt (line 6)) (0.85.0)\n",
            "Requirement already satisfied: uvicorn in ./venv/lib/python3.7/site-packages (from -r requirements.txt (line 7)) (0.18.3)\n",
            "Requirement already satisfied: omegaconf in ./venv/lib/python3.7/site-packages (from -r requirements.txt (line 8)) (2.2.3)\n",
            "Requirement already satisfied: transformers in ./venv/lib/python3.7/site-packages (from -r requirements.txt (line 9)) (4.23.1)\n",
            "Requirement already satisfied: sentence_transformers in ./venv/lib/python3.7/site-packages (from -r requirements.txt (line 10)) (2.2.2)\n",
            "Requirement already satisfied: faiss-cpu in ./venv/lib/python3.7/site-packages (from -r requirements.txt (line 11)) (1.7.2)\n",
            "Requirement already satisfied: einops in ./venv/lib/python3.7/site-packages (from -r requirements.txt (line 12)) (0.5.0)\n",
            "Requirement already satisfied: pytorch_lightning in ./venv/lib/python3.7/site-packages (from -r requirements.txt (line 13)) (1.7.7)\n",
            "Requirement already satisfied: ftfy in ./venv/lib/python3.7/site-packages (from -r requirements.txt (line 14)) (6.1.1)\n",
            "Requirement already satisfied: scikit-image in ./venv/lib/python3.7/site-packages (from -r requirements.txt (line 15)) (0.19.3)\n",
            "Requirement already satisfied: torchdiffeq in ./venv/lib/python3.7/site-packages (from -r requirements.txt (line 16)) (0.2.3)\n",
            "Requirement already satisfied: jsonmerge in ./venv/lib/python3.7/site-packages (from -r requirements.txt (line 17)) (1.8.0)\n",
            "Requirement already satisfied: typing-extensions in ./venv/lib/python3.7/site-packages (from torch->-r requirements.txt (line 2)) (4.4.0)\n",
            "Requirement already satisfied: numpy in ./venv/lib/python3.7/site-packages (from torchvision->-r requirements.txt (line 3)) (1.21.6)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./venv/lib/python3.7/site-packages (from torchvision->-r requirements.txt (line 3)) (9.2.0)\n",
            "Requirement already satisfied: requests in ./venv/lib/python3.7/site-packages (from torchvision->-r requirements.txt (line 3)) (2.28.1)\n",
            "Requirement already satisfied: starlette==0.20.4 in ./venv/lib/python3.7/site-packages (from fastapi->-r requirements.txt (line 6)) (0.20.4)\n",
            "Requirement already satisfied: pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2 in ./venv/lib/python3.7/site-packages (from fastapi->-r requirements.txt (line 6)) (1.10.2)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in ./venv/lib/python3.7/site-packages (from starlette==0.20.4->fastapi->-r requirements.txt (line 6)) (3.6.1)\n",
            "Requirement already satisfied: h11>=0.8 in ./venv/lib/python3.7/site-packages (from uvicorn->-r requirements.txt (line 7)) (0.14.0)\n",
            "Requirement already satisfied: click>=7.0 in ./venv/lib/python3.7/site-packages (from uvicorn->-r requirements.txt (line 7)) (8.1.3)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in ./venv/lib/python3.7/site-packages (from omegaconf->-r requirements.txt (line 8)) (6.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in ./venv/lib/python3.7/site-packages (from omegaconf->-r requirements.txt (line 8)) (4.9.3)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in ./venv/lib/python3.7/site-packages (from transformers->-r requirements.txt (line 9)) (0.13.1)\n",
            "Requirement already satisfied: importlib-metadata in ./venv/lib/python3.7/site-packages (from transformers->-r requirements.txt (line 9)) (5.0.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in ./venv/lib/python3.7/site-packages (from transformers->-r requirements.txt (line 9)) (4.64.1)\n",
            "Requirement already satisfied: filelock in ./venv/lib/python3.7/site-packages (from transformers->-r requirements.txt (line 9)) (3.8.0)\n",
            "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.7/site-packages (from transformers->-r requirements.txt (line 9)) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in ./venv/lib/python3.7/site-packages (from transformers->-r requirements.txt (line 9)) (2022.9.13)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in ./venv/lib/python3.7/site-packages (from transformers->-r requirements.txt (line 9)) (0.10.1)\n",
            "Requirement already satisfied: nltk in ./venv/lib/python3.7/site-packages (from sentence_transformers->-r requirements.txt (line 10)) (3.7)\n",
            "Requirement already satisfied: scikit-learn in ./venv/lib/python3.7/site-packages (from sentence_transformers->-r requirements.txt (line 10)) (1.0.2)\n",
            "Requirement already satisfied: scipy in ./venv/lib/python3.7/site-packages (from sentence_transformers->-r requirements.txt (line 10)) (1.7.3)\n",
            "Requirement already satisfied: sentencepiece in ./venv/lib/python3.7/site-packages (from sentence_transformers->-r requirements.txt (line 10)) (0.1.97)\n",
            "Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in ./venv/lib/python3.7/site-packages (from pytorch_lightning->-r requirements.txt (line 13)) (2022.8.2)\n",
            "Requirement already satisfied: pyDeprecate>=0.3.1 in ./venv/lib/python3.7/site-packages (from pytorch_lightning->-r requirements.txt (line 13)) (0.3.2)\n",
            "Requirement already satisfied: torchmetrics>=0.7.0 in ./venv/lib/python3.7/site-packages (from pytorch_lightning->-r requirements.txt (line 13)) (0.10.0)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in ./venv/lib/python3.7/site-packages (from pytorch_lightning->-r requirements.txt (line 13)) (2.10.1)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in ./venv/lib/python3.7/site-packages (from ftfy->-r requirements.txt (line 14)) (0.2.5)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in ./venv/lib/python3.7/site-packages (from scikit-image->-r requirements.txt (line 15)) (2021.11.2)\n",
            "Requirement already satisfied: imageio>=2.4.1 in ./venv/lib/python3.7/site-packages (from scikit-image->-r requirements.txt (line 15)) (2.22.1)\n",
            "Requirement already satisfied: networkx>=2.2 in ./venv/lib/python3.7/site-packages (from scikit-image->-r requirements.txt (line 15)) (2.6.3)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in ./venv/lib/python3.7/site-packages (from scikit-image->-r requirements.txt (line 15)) (1.3.0)\n",
            "Requirement already satisfied: jsonschema in ./venv/lib/python3.7/site-packages (from jsonmerge->-r requirements.txt (line 17)) (4.16.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in ./venv/lib/python3.7/site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning->-r requirements.txt (line 13)) (3.8.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in ./venv/lib/python3.7/site-packages (from packaging>=20.0->transformers->-r requirements.txt (line 9)) (3.0.9)\n",
            "Requirement already satisfied: markdown>=2.6.8 in ./venv/lib/python3.7/site-packages (from tensorboard>=2.9.1->pytorch_lightning->-r requirements.txt (line 13)) (3.4.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in ./venv/lib/python3.7/site-packages (from tensorboard>=2.9.1->pytorch_lightning->-r requirements.txt (line 13)) (2.2.2)\n",
            "Requirement already satisfied: wheel>=0.26 in ./venv/lib/python3.7/site-packages (from tensorboard>=2.9.1->pytorch_lightning->-r requirements.txt (line 13)) (0.37.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in ./venv/lib/python3.7/site-packages (from tensorboard>=2.9.1->pytorch_lightning->-r requirements.txt (line 13)) (0.4.6)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in ./venv/lib/python3.7/site-packages (from tensorboard>=2.9.1->pytorch_lightning->-r requirements.txt (line 13)) (1.49.1)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in ./venv/lib/python3.7/site-packages (from tensorboard>=2.9.1->pytorch_lightning->-r requirements.txt (line 13)) (3.19.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in ./venv/lib/python3.7/site-packages (from tensorboard>=2.9.1->pytorch_lightning->-r requirements.txt (line 13)) (1.8.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in ./venv/lib/python3.7/site-packages (from tensorboard>=2.9.1->pytorch_lightning->-r requirements.txt (line 13)) (1.2.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in ./venv/lib/python3.7/site-packages (from tensorboard>=2.9.1->pytorch_lightning->-r requirements.txt (line 13)) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in ./venv/lib/python3.7/site-packages (from tensorboard>=2.9.1->pytorch_lightning->-r requirements.txt (line 13)) (2.12.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in ./venv/lib/python3.7/site-packages (from tensorboard>=2.9.1->pytorch_lightning->-r requirements.txt (line 13)) (65.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.7/site-packages (from requests->torchvision->-r requirements.txt (line 3)) (3.4)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in ./venv/lib/python3.7/site-packages (from requests->torchvision->-r requirements.txt (line 3)) (2.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.7/site-packages (from requests->torchvision->-r requirements.txt (line 3)) (2022.9.24)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./venv/lib/python3.7/site-packages (from requests->torchvision->-r requirements.txt (line 3)) (1.26.12)\n",
            "Requirement already satisfied: zipp>=0.5 in ./venv/lib/python3.7/site-packages (from importlib-metadata->transformers->-r requirements.txt (line 9)) (3.9.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in ./venv/lib/python3.7/site-packages (from jsonschema->jsonmerge->-r requirements.txt (line 17)) (22.1.0)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in ./venv/lib/python3.7/site-packages (from jsonschema->jsonmerge->-r requirements.txt (line 17)) (5.10.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in ./venv/lib/python3.7/site-packages (from jsonschema->jsonmerge->-r requirements.txt (line 17)) (0.18.1)\n",
            "Requirement already satisfied: pkgutil-resolve-name>=1.3.10 in ./venv/lib/python3.7/site-packages (from jsonschema->jsonmerge->-r requirements.txt (line 17)) (1.3.10)\n",
            "Requirement already satisfied: joblib in ./venv/lib/python3.7/site-packages (from nltk->sentence_transformers->-r requirements.txt (line 10)) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in ./venv/lib/python3.7/site-packages (from scikit-learn->sentence_transformers->-r requirements.txt (line 10)) (3.1.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in ./venv/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning->-r requirements.txt (line 13)) (4.0.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in ./venv/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning->-r requirements.txt (line 13)) (6.0.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in ./venv/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning->-r requirements.txt (line 13)) (1.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in ./venv/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning->-r requirements.txt (line 13)) (1.8.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in ./venv/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning->-r requirements.txt (line 13)) (1.2.0)\n",
            "Requirement already satisfied: asynctest==0.13.0 in ./venv/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning->-r requirements.txt (line 13)) (0.13.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in ./venv/lib/python3.7/site-packages (from anyio<5,>=3.4.0->starlette==0.20.4->fastapi->-r requirements.txt (line 6)) (1.3.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in ./venv/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch_lightning->-r requirements.txt (line 13)) (5.2.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in ./venv/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch_lightning->-r requirements.txt (line 13)) (4.9)\n",
            "Requirement already satisfied: six>=1.9.0 in ./venv/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch_lightning->-r requirements.txt (line 13)) (1.16.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./venv/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch_lightning->-r requirements.txt (line 13)) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in ./venv/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->pytorch_lightning->-r requirements.txt (line 13)) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in ./venv/lib/python3.7/site-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->pytorch_lightning->-r requirements.txt (line 13)) (2.1.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in ./venv/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch_lightning->-r requirements.txt (line 13)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in ./venv/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->pytorch_lightning->-r requirements.txt (line 13)) (3.2.1)\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 33.0M  100 33.0M    0     0  73.2M      0 --:--:-- --:--:-- --:--:--  134M\n"
          ]
        }
      ],
      "source": [
        "%cd /content/naifu\n",
        "!pip install virtualenv && bash ./setup.sh\n",
        "!curl -Ls https://github.com/ekzhang/bore/releases/download/v0.4.0/bore-v0.4.0-x86_64-unknown-linux-musl.tar.gz | tar zx -C /usr/bin\n",
        "!curl -Lo /usr/bin/cloudflared https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64 && chmod +x /usr/bin/cloudflared"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8uY16kgGHrw"
      },
      "source": [
        "3. 启动模型，访问输出的映射地址（以 `trycloudflare.com` / `bore.pub` 结尾）即可。\n",
        "   - 请等待模型加载完成（出现`Application startup complete`字样）再访问\n",
        "   - cloudflare 提供的服务偶尔会出现请求超时，可换用 bore 隧道"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQBR9zXQGJrn",
        "outputId": "03d8e921-4601-4f2c-d107-328b874fc298"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: '/content/naifu'\n",
            "/content\n",
            "sed: can't read run.sh: No such file or directory\n",
            "/bin/bash: cloudflared: command not found\n",
            "bash: run.sh: No such file or directory\n"
          ]
        }
      ],
      "source": [
        "%cd /content/naifu\n",
        "!sed -i 's/# export SAVE_FILES=\"1\"/export SAVE_FILES=\"1\"/g' run.sh\n",
        "!bash run.sh & cloudflared tunnel --url localhost:6969"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mh-sRTlMyVDD"
      },
      "source": [
        "4. (可选）默认使用的是 4G 大小的 `animefull-final-pruned` 模型。如果想使用 7G 的 `animefull-latest` 模型，运行这个"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9j9thAby5_2",
        "outputId": "2f995a95-0a4b-4582-84de-7c160d532897"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n",
            "/content/naifu\n",
            "env: DTYPE=float16\n",
            "env: CLIP_CONTEXTS=3\n",
            "env: AMP=1\n",
            "env: MODEL=stable-diffusion\n",
            "env: DEV=True\n",
            "env: MODEL_PATH=models/animefull-latest\n",
            "env: ENABLE_EMA=1\n",
            "env: VAE_PATH=models/animevae.pt\n",
            "env: PENULTIMATE=1\n",
            "env: PYTHONDONTWRITEBYTECODE=1\n",
            "env: SAVE_FILES=1\n",
            "\u001b[2m2022-10-13T01:02:10.526801Z\u001b[0m \u001b[32m INFO\u001b[0m \u001b[2mbore_cli::client\u001b[0m\u001b[2m:\u001b[0m connected to server \u001b[3mremote_port\u001b[0m\u001b[2m=\u001b[0m34839\n",
            "\u001b[2m2022-10-13T01:02:10.526967Z\u001b[0m \u001b[32m INFO\u001b[0m \u001b[2mbore_cli::client\u001b[0m\u001b[2m:\u001b[0m listening at bore.pub:34839\n",
            "\u001b[90m2022-10-13T01:02:10Z\u001b[0m \u001b[32mINF\u001b[0m Thank you for trying Cloudflare Tunnel. Doing so, without a Cloudflare account, is a quick way to experiment and try it out. However, be aware that these account-less Tunnels have no uptime guarantee. If you intend to use Tunnels in production you should use a pre-created named tunnel by following: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps\n",
            "\u001b[90m2022-10-13T01:02:10Z\u001b[0m \u001b[32mINF\u001b[0m Requesting new quick Tunnel on trycloudflare.com...\n",
            "\u001b[90m2022-10-13T01:02:13Z\u001b[0m \u001b[32mINF\u001b[0m +--------------------------------------------------------------------------------------------+\n",
            "\u001b[90m2022-10-13T01:02:13Z\u001b[0m \u001b[32mINF\u001b[0m |  Your quick Tunnel has been created! Visit it at (it may take some time to be reachable):  |\n",
            "\u001b[90m2022-10-13T01:02:13Z\u001b[0m \u001b[32mINF\u001b[0m |  https://velocity-los-pixel-guilty.trycloudflare.com                                       |\n",
            "\u001b[90m2022-10-13T01:02:13Z\u001b[0m \u001b[32mINF\u001b[0m +--------------------------------------------------------------------------------------------+\n",
            "\u001b[90m2022-10-13T01:02:13Z\u001b[0m \u001b[32mINF\u001b[0m Cannot determine default configuration path. No file [config.yml config.yaml] in [~/.cloudflared ~/.cloudflare-warp ~/cloudflare-warp /etc/cloudflared /usr/local/etc/cloudflared]\n",
            "\u001b[90m2022-10-13T01:02:13Z\u001b[0m \u001b[32mINF\u001b[0m Version 2022.10.0\n",
            "\u001b[90m2022-10-13T01:02:13Z\u001b[0m \u001b[32mINF\u001b[0m GOOS: linux, GOVersion: go1.18.6, GoArch: amd64\n",
            "\u001b[90m2022-10-13T01:02:13Z\u001b[0m \u001b[32mINF\u001b[0m Settings: map[protocol:quic url:localhost:6969]\n",
            "\u001b[90m2022-10-13T01:02:13Z\u001b[0m \u001b[32mINF\u001b[0m Generated Connector ID: 34ef6d52-2f01-4bd9-8895-2d286ad447e5\n",
            "\u001b[90m2022-10-13T01:02:13Z\u001b[0m \u001b[32mINF\u001b[0m cloudflared will not automatically update when run from the shell. To enable auto-updates, run cloudflared as a service: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps/run-tunnel/as-a-service/\n",
            "\u001b[90m2022-10-13T01:02:13Z\u001b[0m \u001b[32mINF\u001b[0m Initial protocol quic\n",
            "\u001b[90m2022-10-13T01:02:13Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use 172.28.0.2 as source for IPv4\n",
            "\u001b[90m2022-10-13T01:02:13Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use :: as source for IPv6\n",
            "\u001b[90m2022-10-13T01:02:13Z\u001b[0m \u001b[31mWRN\u001b[0m The user running cloudflared process has a GID (group ID) that is not within ping_group_range. You might need to add that user to a group within that range, or instead update the range to encompass a group the user is already in by modifying /proc/sys/net/ipv4/ping_group_range. Otherwise cloudflared will not be able to ping this network \u001b[31merror=\u001b[0m\u001b[31m\"Group ID 0 is not between ping group 1 to 0\"\u001b[0m\n",
            "\u001b[90m2022-10-13T01:02:13Z\u001b[0m \u001b[31mWRN\u001b[0m ICMP proxy feature is disabled \u001b[31merror=\u001b[0m\u001b[31m\"cannot create ICMPv4 proxy: Group ID 0 is not between ping group 1 to 0 nor ICMPv6 proxy: socket: permission denied\"\u001b[0m\n",
            "\u001b[90m2022-10-13T01:02:13Z\u001b[0m \u001b[32mINF\u001b[0m Starting metrics server on 127.0.0.1:37169/metrics\n",
            "2022/10/13 01:02:13 failed to sufficiently increase receive buffer size (was: 208 kiB, wanted: 2048 kiB, got: 416 kiB). See https://github.com/lucas-clemente/quic-go/wiki/UDP-Receive-Buffer-Size for details.\n",
            "\u001b[90m2022-10-13T01:02:13Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Failed to serve quic connection \u001b[31merror=\u001b[0m\u001b[31m\"Unauthorized: Failed to get tunnel\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.53\n",
            "\u001b[90m2022-10-13T01:02:13Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Register tunnel error from server side \u001b[31merror=\u001b[0m\u001b[31m\"Unauthorized: Failed to get tunnel\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.53\n",
            "\u001b[90m2022-10-13T01:02:13Z\u001b[0m \u001b[32mINF\u001b[0m Retrying connection in up to 2s seconds \u001b[36mconnIndex=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.53\n",
            "\u001b[90m2022-10-13T01:02:14Z\u001b[0m \u001b[32mINF\u001b[0m Connection fefb5a92-a7a8-4c46-9ad2-9b97232763d0 registered \u001b[36mconnIndex=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.53 \u001b[36mlocation=\u001b[0mSJC\n",
            "\u001b[90m2022-10-13T01:02:14Z\u001b[0m \u001b[32mINF\u001b[0m Connection 32faf552-68df-472d-9ac3-1eee0206089c registered \u001b[36mconnIndex=\u001b[0m1 \u001b[36mip=\u001b[0m198.41.192.107 \u001b[36mlocation=\u001b[0mLAX\n",
            "Starting Hydra Node HTTP TOKEN=None\n",
            "2022-10-13 01:02:15,520 INFO config.py(596) - CPU: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "2022-10-13 01:02:15,520 INFO config.py(596) - GPU: Tesla T4\n",
            "2022-10-13 01:02:15,521 INFO config.py(596) - GPU RAM: 15gb\n",
            "2022-10-13 01:02:15,521 INFO config.py(596) - MODEL: stable-diffusion\n",
            "2022-10-13 01:02:15,521 INFO models.py(596) - Loading model from folder models/animefull-latest\n",
            "Loading model from models/animefull-latest/model.ckpt\n",
            "\u001b[90m2022-10-13T01:02:15Z\u001b[0m \u001b[32mINF\u001b[0m Connection 5982729c-02d2-4e19-9eb7-3ae644e1f5de registered \u001b[36mconnIndex=\u001b[0m2 \u001b[36mip=\u001b[0m198.41.200.113 \u001b[36mlocation=\u001b[0mSJC\n",
            "\u001b[90m2022-10-13T01:02:16Z\u001b[0m \u001b[32mINF\u001b[0m Connection ac8283d3-7991-4f39-be02-e853ce9649d3 registered \u001b[36mconnIndex=\u001b[0m3 \u001b[36mip=\u001b[0m198.41.192.57 \u001b[36mlocation=\u001b[0mLAX\n",
            "LatentDiffusion: Running in eps-prediction mode\n",
            "DiffusionWrapper has 859.52 M params.\n",
            "Keeping EMAs of 688.\n",
            "making attention of type 'vanilla' with 512 in_channels\n",
            "Working with z of shape (1, 4, 64, 64) = 16384 dimensions.\n",
            "making attention of type 'vanilla' with 512 in_channels\n",
            "Started frozen clip class\n",
            "2022-10-13 01:03:27,287 INFO models.py(596) - Using VAE from models/animevae.pt\n",
            "2022-10-13 01:03:27,287 INFO models.py(596) - CLIP: Using penultimate layer\n",
            "2022-10-13 01:03:27,335 INFO models.py(596) - Using EMA\n",
            "2022-10-13 01:04:02,039 INFO config.py(596) - Models loaded in 106.52s\n",
            "Generating tag embedding index for 39193 tags.\n",
            "Loaded tag suggestion model using phrase embeddings\n",
            "\u001b[32mINFO\u001b[0m:     Started server process [\u001b[36m596\u001b[0m]\n",
            "\u001b[32mINFO\u001b[0m:     Waiting for application startup.\n",
            "2022-10-13 01:04:15,797 INFO main.py(596) - FastAPI Started, serving\n",
            "\u001b[32mINFO\u001b[0m:     Application startup complete.\n",
            "\u001b[32mINFO\u001b[0m:     Uvicorn running on \u001b[1mhttp://0.0.0.0:6969\u001b[0m (Press CTRL+C to quit)\n",
            "\u001b[32mINFO\u001b[0m:     203.91.85.76:0 - \"\u001b[1mGET / HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     203.91.85.76:0 - \"\u001b[1mGET /_next/static/css/32f1e54debdb3c74.css HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     203.91.85.76:0 - \"\u001b[1mGET /_next/static/chunks/main-f17b067b102428ca.js HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     203.91.85.76:0 - \"\u001b[1mGET /_next/static/chunks/pages/index-67838cc9a284731b.js HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     203.91.85.76:0 - \"\u001b[1mGET /_next/static/chunks/webpack-b9b5e27f3c90f79a.js HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     203.91.85.76:0 - \"\u001b[1mGET /_next/static/MG2vPPHR3En34h0ZDGvU7/_buildManifest.js HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     203.91.85.76:0 - \"\u001b[1mGET /_next/static/chunks/pages/_app-128a4b077453e8e5.js HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     203.91.85.76:0 - \"\u001b[1mGET /_next/static/MG2vPPHR3En34h0ZDGvU7/_ssgManifest.js HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     203.91.85.76:0 - \"\u001b[1mGET /_next/static/media/cross.fac5a02a.svg HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     203.91.85.76:0 - \"\u001b[1mGET /_next/static/media/history.b9b000e8.svg HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     34.83.203.92:0 - \"\u001b[1mGET / HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     203.91.85.76:0 - \"\u001b[1mGET /_next/static/media/check.c906eb0a.svg HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     203.91.85.76:0 - \"\u001b[1mGET /_next/static/media/SourceSansPro-Regular.ba487c32.woff2 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     34.83.203.92:0 - \"\u001b[1mGET / HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     34.83.203.92:0 - \"\u001b[1mGET /_next/static/chunks/webpack-b9b5e27f3c90f79a.js HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     34.83.203.92:0 - \"\u001b[1mGET /_next/static/css/32f1e54debdb3c74.css HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     34.83.203.92:0 - \"\u001b[1mGET /_next/static/chunks/pages/_app-128a4b077453e8e5.js HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     34.83.203.92:0 - \"\u001b[1mGET /_next/static/chunks/main-f17b067b102428ca.js HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     34.83.203.92:0 - \"\u001b[1mGET /_next/static/MG2vPPHR3En34h0ZDGvU7/_buildManifest.js HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     34.83.203.92:0 - \"\u001b[1mGET /_next/static/chunks/pages/index-67838cc9a284731b.js HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     34.83.203.92:0 - \"\u001b[1mGET /_next/static/MG2vPPHR3En34h0ZDGvU7/_ssgManifest.js HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     34.83.203.92:0 - \"\u001b[1mGET /_next/static/media/history.b9b000e8.svg HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     34.83.203.92:0 - \"\u001b[1mGET /_next/static/media/SourceSansPro-Regular.ba487c32.woff2 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     34.83.203.92:0 - \"\u001b[1mGET /_next/static/media/cross.fac5a02a.svg HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     34.83.203.92:0 - \"\u001b[1mGET /_next/static/media/check.c906eb0a.svg HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     34.83.203.92:0 - \"\u001b[1mGET /icons/novelai-round.png HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     34.83.203.92:0 - \"\u001b[1mGET /favicon.ico HTTP/1.1\u001b[0m\" \u001b[31m404 Not Found\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     203.91.85.76:0 - \"\u001b[1mGET /manifest.json HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     203.91.85.76:0 - \"\u001b[1mGET /icons/novelai-round.png HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     203.91.85.76:0 - \"\u001b[1mGET /icons/novelai-square.png HTTP/1.1\u001b[0m\" \u001b[31m404 Not Found\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     203.91.85.76:0 - \"\u001b[1mGET /icons/novelai512.png HTTP/1.1\u001b[0m\" \u001b[31m404 Not Found\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     203.91.85.76:0 - \"\u001b[1mGET /_next/static/media/small_cross.8d803d20.svg HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     203.91.85.76:0 - \"\u001b[1mGET /undefined HTTP/1.1\u001b[0m\" \u001b[31m404 Not Found\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     203.91.85.76:0 - \"\u001b[1mGET /_next/static/chunks/247.9ec9f56bc609a550.js HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "2022-10-13 01:04:51,910 INFO main.py(596) - Request took 0.039 seconds\n",
            "\u001b[32mINFO\u001b[0m:     203.91.85.76:0 - \"\u001b[1mGET /predict-tags?prompt=tiny%20breasts HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     203.91.85.76:0 - \"\u001b[1mGET /_next/static/chunks/140.a9739eb472fc0dc3.js HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     203.91.85.76:0 - \"\u001b[1mGET /tokenizer/clip_tokenizer.json?static=true HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "  0% 0/31 [00:00<?, ?it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"./main.py\", line 171, in generate\n",
            "    images = model.sample(request)\n",
            "  File \"/content/naifu/venv/lib/python3.7/site-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/content/naifu/venv/lib/python3.7/site-packages/torch/amp/autocast_mode.py\", line 12, in decorate_autocast\n",
            "    return func(*args, **kwargs)\n",
            "  File \"./hydra_node/models.py\", line 457, in sample\n",
            "    samples = self.sampler_map[request.sampler](self.k_model, start_code, sigmas, request.seed, extra_args=extra_args)\n",
            "  File \"/content/naifu/venv/lib/python3.7/site-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"./k_diffusion/sampling.py\", line 90, in sample_euler_ancestral\n",
            "    denoised = model(x, sigmas[i] * s_in, **extra_args)\n",
            "  File \"/content/naifu/venv/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/content/naifu/venv/lib/python3.7/site-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"./hydra_node/models.py\", line 186, in forward\n",
            "    uncond, cond = self.inner_model(x_two, sigma_two, cond=cond_full).chunk(2)\n",
            "  File \"/content/naifu/venv/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"./k_diffusion/external.py\", line 100, in forward\n",
            "    eps = self.get_eps(input * c_in, self.sigma_to_t(sigma), **kwargs)\n",
            "  File \"./k_diffusion/external.py\", line 126, in get_eps\n",
            "    return self.inner_model.apply_model(*args, **kwargs)\n",
            "  File \"./ldm/models/diffusion/ddpm.py\", line 916, in apply_model\n",
            "    x_recon = self.model(x_noisy, t, **cond)\n",
            "  File \"/content/naifu/venv/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1148, in _call_impl\n",
            "    result = forward_call(*input, **kwargs)\n",
            "  File \"./ldm/models/diffusion/ddpm.py\", line 1378, in forward\n",
            "    out = self.diffusion_model(x, t, context=cc)\n",
            "  File \"/content/naifu/venv/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"./ldm/modules/diffusionmodules/openaimodel.py\", line 784, in forward\n",
            "    h = module(h, emb, context)\n",
            "  File \"/content/naifu/venv/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"./ldm/modules/diffusionmodules/openaimodel.py\", line 87, in forward\n",
            "    x = layer(x, context)\n",
            "  File \"/content/naifu/venv/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"./ldm/modules/attention.py\", line 454, in forward\n",
            "    x = block(x, context=context)\n",
            "  File \"/content/naifu/venv/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"./ldm/modules/attention.py\", line 382, in forward\n",
            "    hidden_states = self.attn1(self.norm1(hidden_states)) + hidden_states\n",
            "  File \"/content/naifu/venv/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"./hydra_node/lowvram.py\", line 151, in split_cross_attention_forward\n",
            "    s2 = s1.softmax(dim=-1, dtype=q.dtype)\n",
            "RuntimeError: CUDA out of memory. Tried to allocate 2.82 GiB (GPU 0; 14.76 GiB total capacity; 7.92 GiB already allocated; 2.53 GiB free; 11.21 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "2022-10-13 01:05:13,915 ERROR main.py(596) - CUDA out of memory. Tried to allocate 2.82 GiB (GPU 0; 14.76 GiB total capacity; 7.92 GiB already allocated; 2.53 GiB free; 11.21 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "2022-10-13 01:05:14,025 ERROR main.py(596) - GPU error, committing seppuku.\n",
            "\u001b[32mINFO\u001b[0m:     203.91.85.76:0 - \"\u001b[1mPOST /generate-stream HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     Shutting down\n",
            "\u001b[32mINFO\u001b[0m:     Waiting for application shutdown.\n",
            "2022-10-13 01:05:14,227 INFO main.py(596) - FastAPI Shutdown, exiting\n",
            "\u001b[32mINFO\u001b[0m:     Application shutdown complete.\n",
            "\u001b[32mINFO\u001b[0m:     Finished server process [\u001b[36m596\u001b[0m]\n",
            "\u001b[90m2022-10-13T01:05:23Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m  \u001b[31merror=\u001b[0m\u001b[31m\"Unable to reach the origin service. The service may be down or it may not be responding to traffic from cloudflared: dial tcp 127.0.0.1:6969: connect: connection refused\"\u001b[0m \u001b[36mcfRay=\u001b[0m75942aa601b8b410-SJC \u001b[36moriginService=\u001b[0mhttp://localhost:6969\n",
            "\u001b[90m2022-10-13T01:05:23Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Request failed \u001b[31merror=\u001b[0m\u001b[31m\"Unable to reach the origin service. The service may be down or it may not be responding to traffic from cloudflared: dial tcp 127.0.0.1:6969: connect: connection refused\"\u001b[0m \u001b[36mconnIndex=\u001b[0m3 \u001b[36mdest=\u001b[0mhttps://velocity-los-pixel-guilty.trycloudflare.com/_next/static/chunks/157.4184b7ea2aeb8d93.js \u001b[36mip=\u001b[0m198.41.192.57 \u001b[36mtype=\u001b[0mhttp\n",
            "\u001b[90m2022-10-13T01:05:51Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m  \u001b[31merror=\u001b[0m\u001b[31m\"Unable to reach the origin service. The service may be down or it may not be responding to traffic from cloudflared: dial tcp 127.0.0.1:6969: connect: connection refused\"\u001b[0m \u001b[36mcfRay=\u001b[0m75942b5487fbb410-SJC \u001b[36moriginService=\u001b[0mhttp://localhost:6969\n",
            "\u001b[90m2022-10-13T01:05:51Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Request failed \u001b[31merror=\u001b[0m\u001b[31m\"Unable to reach the origin service. The service may be down or it may not be responding to traffic from cloudflared: dial tcp 127.0.0.1:6969: connect: connection refused\"\u001b[0m \u001b[36mconnIndex=\u001b[0m3 \u001b[36mdest=\u001b[0mhttps://velocity-los-pixel-guilty.trycloudflare.com/generate-stream \u001b[36mip=\u001b[0m198.41.192.57 \u001b[36mtype=\u001b[0mhttp\n",
            "\u001b[90m2022-10-13T01:05:53Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m  \u001b[31merror=\u001b[0m\u001b[31m\"Unable to reach the origin service. The service may be down or it may not be responding to traffic from cloudflared: dial tcp 127.0.0.1:6969: connect: connection refused\"\u001b[0m \u001b[36mcfRay=\u001b[0m75942b6313a5b410-SJC \u001b[36moriginService=\u001b[0mhttp://localhost:6969\n",
            "\u001b[90m2022-10-13T01:05:53Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Request failed \u001b[31merror=\u001b[0m\u001b[31m\"Unable to reach the origin service. The service may be down or it may not be responding to traffic from cloudflared: dial tcp 127.0.0.1:6969: connect: connection refused\"\u001b[0m \u001b[36mconnIndex=\u001b[0m3 \u001b[36mdest=\u001b[0mhttps://velocity-los-pixel-guilty.trycloudflare.com/generate-stream \u001b[36mip=\u001b[0m198.41.192.57 \u001b[36mtype=\u001b[0mhttp\n",
            "\u001b[90m2022-10-13T01:06:07Z\u001b[0m \u001b[32mINF\u001b[0m Initiating graceful shutdown due to signal interrupt ...\n",
            "\u001b[90m2022-10-13T01:06:08Z\u001b[0m \u001b[32mINF\u001b[0m Unregistered tunnel connection \u001b[36mconnIndex=\u001b[0m2\n",
            "\u001b[90m2022-10-13T01:06:08Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Failed to serve quic connection \u001b[31merror=\u001b[0m\u001b[31m\"context canceled\"\u001b[0m \u001b[36mconnIndex=\u001b[0m2 \u001b[36mip=\u001b[0m198.41.200.113\n",
            "\u001b[90m2022-10-13T01:06:08Z\u001b[0m \u001b[32mINF\u001b[0m Unregistered tunnel connection \u001b[36mconnIndex=\u001b[0m0\n",
            "\u001b[90m2022-10-13T01:06:08Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Failed to serve quic connection \u001b[31merror=\u001b[0m\u001b[31m\"context canceled\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.53\n",
            "\u001b[90m2022-10-13T01:06:08Z\u001b[0m \u001b[32mINF\u001b[0m Unregistered tunnel connection \u001b[36mconnIndex=\u001b[0m3\n",
            "\u001b[90m2022-10-13T01:06:08Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Failed to serve quic connection \u001b[31merror=\u001b[0m\u001b[31m\"context canceled\"\u001b[0m \u001b[36mconnIndex=\u001b[0m3 \u001b[36mip=\u001b[0m198.41.192.57\n",
            "\u001b[90m2022-10-13T01:06:08Z\u001b[0m \u001b[32mINF\u001b[0m Unregistered tunnel connection \u001b[36mconnIndex=\u001b[0m1\n",
            "\u001b[90m2022-10-13T01:06:08Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Failed to serve quic connection \u001b[31merror=\u001b[0m\u001b[31m\"context canceled\"\u001b[0m \u001b[36mconnIndex=\u001b[0m1 \u001b[36mip=\u001b[0m198.41.192.107\n",
            "\u001b[90m2022-10-13T01:06:08Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m no more connections active and exiting\n",
            "\u001b[90m2022-10-13T01:06:08Z\u001b[0m \u001b[32mINF\u001b[0m Tunnel server stopped\n",
            "\u001b[90m2022-10-13T01:06:08Z\u001b[0m \u001b[32mINF\u001b[0m Metrics server stopped\n"
          ]
        }
      ],
      "source": [
        "%cd /content/\n",
        "!tar xf animefull-latest.tar -C /content/naifu/models && rm animefull-latest.tar\n",
        "!sed -i 's/map_location=\"cpu\"/map_location=\"cuda\"/g' /content/naifu/hydra_node/models.py\n",
        "\n",
        "%cd /content/naifu\n",
        "%env DTYPE=float16\n",
        "%env CLIP_CONTEXTS=3\n",
        "%env AMP=1\n",
        "%env MODEL=stable-diffusion\n",
        "%env DEV=True\n",
        "%env MODEL_PATH=models/animefull-latest\n",
        "%env ENABLE_EMA=1\n",
        "%env VAE_PATH=models/animevae.pt\n",
        "%env PENULTIMATE=1\n",
        "%env PYTHONDONTWRITEBYTECODE=1\n",
        "%env SAVE_FILES=1\n",
        "\n",
        "!./venv/bin/python -m uvicorn --host 0.0.0.0 --port=6969 main:app & bore local 6969 --to bore.pub & cloudflared tunnel --url localhost:6969"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}